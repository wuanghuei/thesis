# configs/config.yaml

# Global settings
global:
  project_name: TemporalActionDetection
  seed: 42
  num_classes: 5
  window_size: 32 # Used by base model dataloader & training
  device: cuda

# Data Paths
data:
  base_dir: Data
  # Raw data input directories
  raw_video_dir: Data/Videos_MERL_Shopping_Dataset
  raw_label_dir: Data/Labels_MERL_Shopping_Dataset
  # Processed data output/input directories
  processed_dir: Data/full_videos # Contains frames_npz, annotations_json, pose_npz
  base_model_checkpoints: checkpoints
  rnn_model_checkpoints: rnn_checkpoints
  rnn_processed_data: rnn_processed_data
  logs: logs
  # Specific file names / templates used by different scripts
  base_best_checkpoint_name: best_model.pth
  base_resume_checkpoint_name: interim_model_epoch15.pth # change based on actual file
  rnn_best_checkpoint_name: best_rnn_model.pth
  train_inference_raw_name: train_inference_raw.pkl
  val_inference_raw_name: val_inference_raw.pkl
  test_inference_raw_name: test_inference_raw.pkl # Default for evaluation

# Preprocessing Stage
preprocessing:
  frame_size: 224
  subsample_factor: 2

# Feature Extraction Stage
feature_extraction:
  pose:
    model_complexity: 1
    min_detection_confidence: 0.5

# Base Model Training
base_model_training:
  resume_training: True
  use_mixed_precision: True
  epochs: 100
  batch_size: 1 
  gradient_accumulation_steps: 4
  optimizer:
    type: AdamW
    lr: 1e-5
    weight_decay: 1e-4
    eps: 1e-4
  scheduler: # ReduceLROnPlateau
    factor: 0.2
    patience: 3
    min_lr: 1e-6
  warmup:
    epochs: 7
    factor: 2.5 
  loss:
    action_weight: 1.5
    start_weight: 1.5
    end_weight: 1.5
    label_smoothing: 0.1
  gradient_clipping:
    max_norm: 7.0
  postprocessing: # Heuristic thresholds for base model
    boundary_threshold: 0.11
    class_thresholds: [0.15, 0.15, 0.01, 0.08, 0.15]
    nms_threshold: 0.4
    min_segment_length: 3 
  evaluation: 
    run_final_evaluation_on_test: True
  debugging:
    debug_detection_enabled: True # Enable this to get debug stats
  dataloader:
    num_workers: 4
    batch_size: 1

# RNN Data Generation
rnn_data_generation:
  base_checkpoint_to_use: checkpoints/best_model.pth
  dataloader:
    train_batch_size: 4
    val_batch_size: 8
    num_workers: 0

# RNN Model Training
rnn_training:
  model:
    type: lstm # 'lstm' or 'gru' but we use lstm because it performs better
    hidden_size: 128
    num_layers: 2
    dropout_prob: 0.5
    bidirectional: True
  epochs: 50
  batch_size: 16
  optimizer:
    type: AdamW
    lr: 1e-3
  scheduler: # ReduceLROnPlateau
    factor: 0.5
    patience: 5
  early_stopping:
    patience: 10
  dataloader:
    num_workers: 1
  loss:
    ignore_index: -100 
  val_batch_size: 32

# Pipeline Evaluation
pipeline_evaluation:
  rnn_checkpoint_to_use: rnn_checkpoints/best_rnn_model.pth
  inference_results_pkl: test_inference_raw.pkl # Default to test pkl, adjust if evaluating validation
  visualization:
    enabled: False # Set to True and provide details below to generate visualization
    video_id: null # Specify a video ID like 'subject1_session1_crop'
    frames_npz_template: Data/full_videos/test/frames/{video_id}_frames.npz
    output_video_path: logs/visualization_{video_id}.mp4
    fps: 15 